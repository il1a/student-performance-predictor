{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Models Pipeline Notebook\n",
    "\n",
    "In this notebook, we train two models to predict student exam scores:\n",
    "1. **Artificial Neural Network (ANN)** using TensorFlow\n",
    "2. **Ordinary Least Squares (OLS)** linear regression using Statsmodels\n",
    "\n",
    "The workflow is as follows:\n",
    "- Load the processed training and test data.\n",
    "- Train the ANN, visualize training curves, and evaluate.\n",
    "- Train the OLS model, visualize predictions, and use LinearRegDiagnostic for regression diagnostics.\n",
    "- Save plots to both `/results/plots` and `/docker/images/learningBase`.\n",
    "- Save trained models to `/results/trained_models`.\n",
    "- Compare performance metrics of both approaches.\n"
   ],
   "id": "61f74a169a31e8ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Import Libraries & Setup\n",
   "id": "3edb59de35cc498e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow/Keras for ANN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Statsmodels for OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Sklearn metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# For saving objects\n",
    "import pickle\n",
    "\n",
    "# (Optional) for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define paths (adjust if needed)\n",
    "data_dir = os.path.abspath(os.path.join('..', '..', 'data', 'processed'))\n",
    "train_path = os.path.join(data_dir, 'training_data.csv')\n",
    "test_path = os.path.join(data_dir, 'test_data.csv')\n",
    "\n",
    "# Directory for saving models\n",
    "trained_models_path = os.path.abspath(os.path.join('..','..','results','trained_models'))\n",
    "os.makedirs(trained_models_path, exist_ok=True)\n",
    "\n",
    "# Directory for learning-related outputs (e.g., Docker images)\n",
    "learning_base_path = os.path.abspath(os.path.join('..','..','docker','images','learningBase'))\n",
    "os.makedirs(learning_base_path, exist_ok=True)\n",
    "\n",
    "# Add code directory to system path\n",
    "code_path = os.path.abspath(os.path.join('..'))\n",
    "if code_path not in sys.path:\n",
    "    sys.path.insert(0, code_path)"
   ],
   "id": "f7efcb909b4ebf43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import custom plot saver function\n",
    "from utils.plot_saver import save_plot\n",
    "\n",
    "# Import custom linear regression diagnostic\n",
    "from utils.LinearRegDiagnostic import LinearRegDiagnostic"
   ],
   "id": "24e953dc58222a7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Load Preprocessed Data\n",
   "id": "251139d003cf9e68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Training data path:\", train_path)\n",
    "print(\"Test data path:    \", test_path)\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "target_col = 'Exam_Score'\n",
    "X_train = train_df.drop(columns=[target_col]).values\n",
    "y_train = train_df[target_col].values\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col]).values\n",
    "y_test = test_df[target_col].values"
   ],
   "id": "4ad2c59dc1e0d4f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Artificial Neural Network (ANN)",
   "id": "5ec75293e2b69252"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Define and Compile the Model",
   "id": "f3d6188710d100be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1) # single output for regression\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "id": "cfb820d0b6062059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Train the Model",
   "id": "e85b8422186712ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "a34c65da4e39959a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Visualize Training History",
   "id": "ff10a361e0e90435"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('ANN Training & Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure using custom save_plot (results/plots) and also to learningBase\n",
    "fig_loss = plt.gcf()  # get current figure\n",
    "save_plot(fig_loss, 'ann_loss_curve.png')\n",
    "fig_loss.savefig(os.path.join(learning_base_path, 'ann_loss_curve.png'), bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation MAE\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Test MAE')\n",
    "plt.title('ANN Training & Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "fig_mae = plt.gcf()\n",
    "save_plot(fig_mae, 'ann_mae_curve.png')\n",
    "fig_mae.savefig(os.path.join(learning_base_path, 'ann_mae_curve.png'), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ],
   "id": "7bd2229982c48490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 Evaluate the ANN on the Test Set",
   "id": "5219d15e61264e5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_ANN = model.predict(X_test).flatten()\n",
    "\n",
    "mse_ANN = mean_squared_error(y_test, y_pred_ANN)\n",
    "mae_ANN = mean_absolute_error(y_test, y_pred_ANN)\n",
    "r2_ANN = r2_score(y_test, y_pred_ANN)\n",
    "\n",
    "print(\"=== ANN Performance on Test Set ===\")\n",
    "print(\"MSE :\", mse_ANN)\n",
    "print(\"MAE :\", mae_ANN)\n",
    "print(\"R^2 :\", r2_ANN)"
   ],
   "id": "9d4d2088cddd27b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.5 Scatter Plot of Predictions vs Actual",
   "id": "cf112325bcc2f286"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred_ANN, alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n",
    "plt.xlabel('Actual Exam Score')\n",
    "plt.ylabel('Predicted Exam Score')\n",
    "plt.title('ANN Predictions vs. Actual')\n",
    "\n",
    "fig_scatter_ann = plt.gcf()\n",
    "save_plot(fig_scatter_ann, 'ann_predictions_scatter.png')\n",
    "fig_scatter_ann.savefig(os.path.join(learning_base_path, 'ann_predictions_scatter.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "4de57eac9e5ef592",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.6 Residual Distribution Plot",
   "id": "afd2a38ca8158314"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "residuals_ANN = y_test - y_pred_ANN\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals_ANN, kde=True)\n",
    "plt.title('ANN Residual Distribution')\n",
    "plt.xlabel('Residual (Actual - Predicted)')\n",
    "\n",
    "fig_resid_ann = plt.gcf()\n",
    "save_plot(fig_resid_ann, 'ann_residual_distribution.png')\n",
    "fig_resid_ann.savefig(os.path.join(learning_base_path, 'ann_residual_distribution.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "1e3d05051ef6543a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.7 Save the Trained ANN Model",
   "id": "d92c1c2b778899c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ann_model_path = os.path.join(trained_models_path, 'currentAiSolution.keras')\n",
    "model.save(ann_model_path)\n",
    "print(f\"ANN model saved at: {ann_model_path}\")\n",
    "\n",
    "# Save training history as CSV\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv_path = os.path.join(trained_models_path, 'ann_training_metrics.csv')\n",
    "history_df.to_csv(history_csv_path, index=False)\n",
    "print(f\"ANN training metrics saved to {history_csv_path}\")"
   ],
   "id": "ca4be3a8f29a805b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Ordinary Least Squares (OLS) with Statsmodels\n"
   ],
   "id": "6ab80fe9003349ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_ols = sm.add_constant(X_train)\n",
    "X_test_ols = sm.add_constant(X_test)\n",
    "\n",
    "ols_model = sm.OLS(y_train, X_train_ols).fit()\n",
    "print(ols_model.summary())\n",
    "\n",
    "y_pred_OLS = ols_model.predict(X_test_ols)\n",
    "\n",
    "mse_OLS = mean_squared_error(y_test, y_pred_OLS)\n",
    "mae_OLS = mean_absolute_error(y_test, y_pred_OLS)\n",
    "r2_OLS = r2_score(y_test, y_pred_OLS)\n",
    "\n",
    "print(\"\\n=== OLS Performance on Test Set ===\")\n",
    "print(\"MSE :\", mse_OLS)\n",
    "print(\"MAE :\", mae_OLS)\n",
    "print(\"R^2 :\", r2_OLS)"
   ],
   "id": "11ee8194867ef750",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Scatter Plot of OLS Predictions vs Actual",
   "id": "17fbf2d574beaf0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred_OLS, alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n",
    "plt.xlabel('Actual Exam Score')\n",
    "plt.ylabel('Predicted Exam Score')\n",
    "plt.title('OLS Predictions vs. Actual')\n",
    "\n",
    "fig_scatter_ols = plt.gcf()\n",
    "save_plot(fig_scatter_ols, 'ols_predictions_scatter.png')\n",
    "fig_scatter_ols.savefig(os.path.join(learning_base_path, 'ols_predictions_scatter.png'), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "67531c4c9092ce11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2 Linear Regression Diagnostics Using `LinearRegDiagnostic`\n",
   "id": "b82fe326d37a8afa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create an instance of the diagnostic class with the fitted OLS model\n",
    "diag = LinearRegDiagnostic(ols_model)\n",
    "\n",
    "# Generate all diagnostic plots (they appear as a 2×2 figure)\n",
    "vif_table, fig_diagnostics, ax = diag()\n",
    "\n",
    "# Save the 2×2 subplot figure to learningBase\n",
    "diag_pdf_path = os.path.join(learning_base_path, 'OLS_DiagnosticPlots.pdf')\n",
    "fig_diagnostics.savefig(diag_pdf_path, format='pdf', bbox_inches='tight')\n",
    "print(f\"Diagnostic plots saved to PDF: {diag_pdf_path}\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "881e452f04c4dec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Save the OLS Model\n",
   "id": "5553c25782ed6ba7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ols_model_path = os.path.join(trained_models_path, 'currentOlsSolution.pkl')\n",
    "with open(ols_model_path, 'wb') as f:\n",
    "    pickle.dump(ols_model, f)\n",
    "\n",
    "print(f\"OLS model saved at: {ols_model_path}\")\n",
    "\n",
    "# Save the OLS summary to a text file\n",
    "ols_summary_path = os.path.join(trained_models_path, 'ols_model_summary.txt')\n",
    "with open(ols_summary_path, 'w') as f:\n",
    "    f.write(str(ols_model.summary()))\n",
    "\n",
    "print(f\"OLS summary saved at: {ols_summary_path}\")"
   ],
   "id": "5f45768c2f8b69f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. Compare Model Performance\n"
   ],
   "id": "59c161d47553d3a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": [\"ANN\", \"OLS\"],\n",
    "    \"MSE\": [mse_ANN, mse_OLS],\n",
    "    \"MAE\": [mae_ANN, mae_OLS],\n",
    "    \"R^2\": [r2_ANN, r2_OLS]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "print(comparison_df)"
   ],
   "id": "543578bdcf07d60a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
